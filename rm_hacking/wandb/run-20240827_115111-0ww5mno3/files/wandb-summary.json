{"train/policy_loss": -0.0009726532443892211, "train/actor_lr": 4.902049104416051e-07, "train/kl": 0.01716264776566339, "train/reward": -1.282094955444336, "train/return": -1.4524138802662492, "train/response_length": 991.4140625, "train/total_length": 998.4140625, "train/critic_loss": 0.0017038194252450012, "train/values": -1.3333740234375, "train/critic_lr": 8.823688105508154e-06, "train/global_step": 8, "_timestamp": 1724769820.319957, "_runtime": 10349.066577911377, "_step": 7}